{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cbee35",
   "metadata": {
    "id": "48cbee35"
   },
   "source": [
    "# <font color=\"red\"> MBA em IA e Big Data</font>\n",
    "## <span style=\"color:red\">Curso 03: Gerenciamento e Processamento Paralelo de Dados em Larga Escala</span>\n",
    "\n",
    "### <span style=\"color:darkred\">Classificação PySpark com o algoritmo Logistic Regression e múltiplos classificadores</span>\n",
    "\n",
    "*Prof. Dr. Jose Fernando Rodrigues Junior*<br>\n",
    "*ICMC-USP São Carlos*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7575cd1-1322-4c79-ab04-b73e93812818",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003674ab-e0c7-4a00-911d-460a4b928b9b",
   "metadata": {},
   "source": [
    "O algoritmo de Regressão Logística é um método de aprendizado supervisionado utilizado para resolver problemas de classificação binária, onde o objetivo é prever a probabilidade de uma observação pertencer a uma das duas classes. Ele funciona modelando a relação entre as variáveis independentes (características) e a variável dependente binária (classe) usando a função logística (ou sigmoide), que mapeia qualquer valor real em um intervalo entre 0 e 1. A função logística é definida como \\( \\sigma(z) = \\frac{1}{1 + e^{-z}} \\), onde \\( z \\) é uma combinação linear das variáveis de entrada. A Regressão Logística ajusta os pesos das características minimizando uma função de custo, geralmente a perda logarítmica, para maximizar a verossimilhança da probabilidade de observação dos dados. O resultado final é um modelo que fornece probabilidades para a classificação, com um limiar que define em qual das duas classes a observação deve ser categorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8d5c73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "error",
     "timestamp": 1724170492310,
     "user": {
      "displayName": "José Fernando Rodrigues Junior",
      "userId": "16173600431460248690"
     },
     "user_tz": 180
    },
    "id": "5a8d5c73",
    "outputId": "6c9ca5e5-8e66-42d7-a84b-85fc4a118fcd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d42417-7a1f-45fc-a9df-cdd3e52a5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"LogisticRegressionIris\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c38c2d9d-6cfe-466d-9b9b-f4e88751db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset in libsvm format\n",
    "data = spark.read.format(\"libsvm\").load(\"iris.txt\")\n",
    "\n",
    "# Show the schema to verify\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c80d31f1-b4d4-48df-a421-f2062ac45fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train, test = data.randomSplit([0.7, 0.3], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rtEuVVCBs3-C",
   "metadata": {
    "id": "rtEuVVCBs3-C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the LogisticRegression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, family=\"multinomial\")\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9afacfc-c923-4631-ad08-67311e8c1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions using the test dataset\n",
    "predictions = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a87418bc-9cd5-41b4-9672-15ba83028904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9250\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print out the accuracy\n",
    "print(f\"Test set accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd7a038-9a68-4ad5-b7ff-d66a0a488af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----+----------+\n",
      "|                                          features|label|prediction|\n",
      "+--------------------------------------------------+-----+----------+\n",
      "|   (4,[0,1,2,3],[-0.166667,-0.416667,0.38983,0.5])|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[-0.166667,-0.333333,0.38983,0.916...|  0.0|       0.0|\n",
      "|   (4,[0,1,2,3],[0.111111,-0.583333,0.355932,0.5])|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.111111,-0.416667,0.322034,0.416...|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.111111,-0.333333,0.38983,0.1666...|  0.0|       2.0|\n",
      "|  (4,[0,1,2,3],[0.111111,-0.25,0.559322,0.416667])|  0.0|       0.0|\n",
      "|   (4,[0,1,2,3],[0.111111,0.0833333,0.694915,1.0])|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.333333,0.0833333,0.59322,0.6666...|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.444444,-0.0833334,0.38983,0.833...|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.444444,-0.0833334,0.491525,0.66...|  0.0|       0.0|\n",
      "|  (4,[0,1,2,3],[0.611111,-0.166667,0.627119,0.25])|  0.0|       2.0|\n",
      "|(4,[0,1,2,3],[0.833333,-0.166667,0.898305,0.666...|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[0.888889,-0.166667,0.728813,0.833...|  0.0|       0.0|\n",
      "|        (4,[0,1,2,3],[0.888889,0.5,0.932203,0.75])|  0.0|       0.0|\n",
      "|         (4,[0,1,2,3],[1.0,0.5,0.830508,0.583333])|  0.0|       0.0|\n",
      "|(4,[0,1,2,3],[-0.944444,-0.25,-0.864407,-0.9166...|  1.0|       1.0|\n",
      "|(4,[0,1,2,3],[-0.833333,-0.0833334,-0.830508,-0...|  1.0|       1.0|\n",
      "|(4,[0,1,2,3],[-0.722222,-0.166667,-0.864407,-0....|  1.0|       1.0|\n",
      "|(4,[0,1,2,3],[-0.666667,-0.0833334,-0.830508,-1...|  1.0|       1.0|\n",
      "|(4,[0,1,2,3],[-0.611111,0.25,-0.898305,-0.833333])|  1.0|       1.0|\n",
      "+--------------------------------------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(truncate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2692b2e5-8fe8-4fd3-83ae-669de83c0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dwWE3XOsov6",
   "metadata": {
    "id": "7dwWE3XOsov6"
   },
   "source": [
    "**MULTIPLE CLASSIFIERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "139665ed-8d88-4f71-9be5-ce0fa88b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d702b865-6c99-45bf-ae08-1654d1396d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"MultipleClassifiersOnIris\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f37a628-80aa-419d-9e68-51c2cee2f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset in libsvm format\n",
    "data = spark.read.format(\"libsvm\").load(\"iris.txt\")\n",
    "\n",
    "# Show the schema to verify\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bc2a299-8580-4fa6-8e46-bf9912808269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ee66a7-2dd0-4f59-9dca-a643ccf9c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to evaluate\n",
    "classifiers = [\n",
    "    LogisticRegression(maxIter=10, featuresCol=\"features\", labelCol=\"label\"),\n",
    "    DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    RandomForestClassifier(numTrees=10, featuresCol=\"features\", labelCol=\"label\"),\n",
    "    MultilayerPerceptronClassifier(maxIter=100, layers=[4, 5, 4, 3], blockSize=128, seed=1234, featuresCol=\"features\", labelCol=\"label\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5b78bcf-5e0b-4605-b1dc-1afbdb030b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17d2cb99-032b-4a64-9a48-a3dcbeb3f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy with LogisticRegression = 0.9762\n",
      "Test set accuracy with DecisionTreeClassifier = 0.9524\n",
      "Test set accuracy with RandomForestClassifier = 0.9524\n",
      "Test set accuracy with MultilayerPerceptronClassifier = 0.9762\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the classifiers, fit the model, and evaluate accuracy\n",
    "for classifier in classifiers:\n",
    "    # Train the model\n",
    "    model = classifier.fit(train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    # Print out the classifier name and its test set accuracy\n",
    "    print(f\"Test set accuracy with {classifier.__class__.__name__} = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e0a2b56-8271-4f4b-8c9e-e9c4aa0c0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
